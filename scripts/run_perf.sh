# python3 ./benchmarks/benchmark_latency.py --model ./models/Llama-3.2-3B-Instruct/  --input-len 4096 --output-len 100 --batch-size 1
python3 ./benchmarks/benchmark_latency.py --model /root/autodl-tmp/meta-llama+Llama-3.2-3B-Instruct/  --input-len 4096 --output-len 100 --batch-size 1