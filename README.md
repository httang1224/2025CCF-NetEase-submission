# ğŸš€ é¢å‘å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å°å‹åŒ–éƒ¨ç½²ä¼˜åŒ–æ–¹æ³•ç ”ç©¶

æœ¬é¡¹ç›®æ—¨åœ¨ç ”ç©¶å¦‚ä½•åœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°å¤§æ¨¡å‹åœ¨æœ‰é™ç®—åŠ›å¹³å°ä¸Šçš„é«˜æ•ˆéƒ¨ç½²ã€‚æˆ‘ä»¬ä»¥ **LLaMA-3.2-3B-Instruct** ä¸ºåŸºå‡†æ¨¡å‹ï¼Œé‡‡ç”¨ **GPTQ** å’Œ **AWQ** è¿›è¡Œé‡åŒ–å‹ç¼©ï¼Œå¹¶ç»“åˆ `vLLM` ä¸ `lm-evaluation-harness` å·¥å…·ï¼Œå¯¹æ¨¡å‹åœ¨ **å‡†ç¡®ç‡ä¸æ¨ç†å»¶è¿Ÿ** ä¸¤æ–¹é¢è¿›è¡Œç³»ç»Ÿè¯„ä¼°ã€‚

---

## ğŸ“Š 1. é‡åŒ–æ€§èƒ½å¯¹æ¯”å›¾

<p align="center">
  <img src="./scripts/assets/gsm_arc.png" width="1000"/>
</p>

---

## ğŸ—‚ï¸ 2. é¡¹ç›®ç»“æ„

```text
.
â”œâ”€â”€ benchmarks/                    # ğŸš¦ æ¨ç†å»¶è¿Ÿè¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ benchmark_latency.py
â”‚   â””â”€â”€ benchmark_utils.py
â”œâ”€â”€ models/                        # ğŸ§  åŸå§‹/é‡åŒ–æ¨¡å‹å­˜æ”¾ç›®å½•
â”‚   â””â”€â”€ Llama-3.2-3B-Instruct/
â”œâ”€â”€ outputs/                       # ğŸ“ ç²¾åº¦ä¸æ€§èƒ½è¯„ä¼°ç»“æœ
â”‚   â”œâ”€â”€ acc.json
â”‚   â””â”€â”€ perf.json
â”œâ”€â”€ scripts/                       # ğŸ› ï¸ ç¯å¢ƒéƒ¨ç½²ã€æ¨¡å‹ä¸‹è½½è„šæœ¬
â”‚   â””â”€â”€ install_env.sh
â””â”€â”€ ...
```

---

## ğŸ§± 3. ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…

```bash
git clone git@github.com:httang1224/2025CCF-NetEase-submission.git
cd 2025CCF-NetEase-submission
chmod +x install_env.sh
./install_env.sh
conda activate llm_compress
```

---

## ğŸ“¦ 4. åŸå§‹æ¨¡å‹ä¸‹è½½ä¸å‡†å¤‡

```bash
export HF_ENDPOINT=https://hf-mirror.com

huggingface-cli download --token <your_token> --resume-download \
  meta-llama/Llama-3.2-3B-Instruct \
  --local-dir ./models/Llama-3.2-3B-Instruct
```

---

## ğŸ”¬ 5. åŸå§‹æ¨¡å‹æ€§èƒ½åŸºå‡†è¯„ä¼°

### â±ï¸ 5.1 æ¨ç†å»¶è¿Ÿè¯„ä¼°

```bash
python3 ./benchmarks/benchmark_latency.py \
  --model ./models/Llama-3.2-3B-Instruct/ \
  --input-len 4096 --output-len 100 --batch-size 1
```

```
TTFT: 0.2929 s
TPOT: 0.0151 s
weights_memory: 6127.83 MB
```

### ğŸ§ª 5.2 ç²¾åº¦è¯„ä¼°

#### ğŸ“˜ GSM8Kï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜

```bash
lm-eval --model vllm \
  --model_args pretrained=./models/Llama-3.2-3B-Instruct/,gpu_memory_utilization=0.6,dtype=auto \
  --tasks gsm8k \
  --batch_size auto:1 \
  --output_path ./outputs/
```

```
|Tasks|Version|Filter|n-shot|Metric| |Value| |Stderr|
|-----|------:|------|-----:|------|-|-----:|-|------:|
|gsm8k|     3 |flexible-extract|5|exact_match|â†‘|0.6543|Â±|0.0131|
|     |       |strict-match    |5|exact_match|â†‘|0.6482|Â±|0.0132|
```

#### ğŸ§ª ARC-Challengeï¼šç§‘å­¦é€‰æ‹©é¢˜

```bash
lm-eval --model vllm \
  --model_args pretrained=./models/Llama-3.2-3B-Instruct/,gpu_memory_utilization=0.6,dtype=auto \
  --tasks arc_challenge \
  --batch_size auto:1 \
  --output_path ./outputs/
```

```
|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|-------------|------:|------|-----:|--------|---|-----:|---|-----:|
|arc_challenge|      1|none  |     0|acc     |â†‘  |0.4352|Â±  |0.0145|
|             |       |none  |     0|acc_norm|â†‘  |0.4582|Â±  |0.0146|
```

---

## ğŸ”§ 6. é‡åŒ–æ¨¡å‹è¯„ä¼°

### âš™ï¸ 6.1 ä½¿ç”¨ GPTQ è¿›è¡Œé‡åŒ–

```bash
python GPTQ_v1.py
```

### ğŸ§ª 6.2 é‡åŒ–æ¨¡å‹ç²¾åº¦è¯„ä¼°

```bash
chmod +x evaluate.sh
./evaluate.sh ./models/Int8_gptq_v1
```

### ğŸ› ï¸ 6.3 ä½¿ç”¨ AWQ è¿›è¡Œé‡åŒ–ï¼ˆå¼€å‘ä¸­ï¼‰

```bash
# TODO: æ·»åŠ  AWQ é‡åŒ–æµç¨‹
```

---

## ğŸ† 7. æ¯”èµ›è¯„åˆ†æŒ‡æ ‡è¯´æ˜

### ğŸ¯ 7.1 ç²¾åº¦æŒ‡æ ‡ï¼ˆAccuracyï¼‰

æ¨¡å‹åœ¨ `ARC-Challenge` ä¸ `GSM8K` ä»»åŠ¡ä¸Šçš„å¹³å‡å¾—åˆ†ï¼š

- ğŸ“Š **å‚è€ƒåŸºçº¿**ï¼šåŸå§‹æ¨¡å‹åˆ†æ•°ï¼ˆLLaMA-3.2-3B-Instructï¼‰
- ğŸš€ **ä¼˜åŒ–ç›®æ ‡**ï¼šä½ ä¼˜åŒ–åçš„å‹ç¼©æ¨¡å‹å¾—åˆ†

### âš¡ 7.2 æ€§èƒ½æŒ‡æ ‡ï¼ˆEfficiencyï¼‰

- ğŸ“‰ æ¨¡å‹å‹ç¼©ç‡ï¼ˆæ¨¡å‹æ–‡ä»¶ä½“ç§¯å¯¹æ¯”ï¼‰
- âš¡ æ¨ç†é€Ÿåº¦æå‡ï¼š
  - TTFTï¼ˆTime to First Tokenï¼‰
  - TPOTï¼ˆTime Per Output Tokenï¼‰

æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡ç›¸è¾ƒåŸå§‹æ¨¡å‹è¿›è¡Œæ¯”å€¼è®¡ç®—ã€‚

### ğŸ§® 7.3 æ€»åˆ†è®¡ç®—æ–¹å¼

> æ‰€æœ‰æŒ‡æ ‡å°†å½’ä¸€åŒ–ååŠ æƒæ±‚å’Œï¼Œä½œä¸ºæœ€ç»ˆå¾—åˆ†ã€‚

---

## ğŸ–¥ï¸ 8. å®éªŒç¡¬ä»¶è¯´æ˜

> âš ï¸ è™½ç„¶å®˜æ–¹æ¨èä½¿ç”¨ RTX 4090ï¼Œæœ¬é¡¹ç›®è¯„ä¼°å®æµ‹å¹³å°ä¸º **NVIDIA A40 48GB**ï¼Œç¡®ä¿è¯„ä¼°æ•°æ®ç¨³å®šã€å¯å¤ç°ã€‚

---