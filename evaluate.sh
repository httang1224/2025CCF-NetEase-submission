#!/bin/bash

# ===============================
# LLaMA æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼ˆåªæ”¯æŒä¼ å…¥æ¨¡å‹è·¯å¾„ï¼‰
# ===============================

# è·å–ä¼ å…¥æ¨¡å‹è·¯å¾„ï¼Œè‹¥æœªä¼ å…¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
MODEL_PATH=${1:-"./models/Llama-3.2-3B-Instruct"}
OUTPUT_PATH="./outputs"
GPU_UTILIZATION=0.6
DTYPE="auto"
BATCH_SIZE="auto:1"
INPUT_LEN=4096
OUTPUT_LEN=100

echo "ğŸ”§ å¾…è¯„ä¼°æ¨¡å‹è·¯å¾„: $MODEL_PATH"
echo "ğŸ“‚ è¾“å‡ºç›®å½•: $OUTPUT_PATH"
echo "==============================="

echo "ğŸš€ å¼€å§‹æ¨ç†å»¶è¿Ÿè¯„ä¼°..."
python3 ./benchmarks/benchmark_latency.py \
  --model "$MODEL_PATH" \
  --input-len $INPUT_LEN \
  --output-len $OUTPUT_LEN \
  --batch-size 1

echo "âœ… å»¶è¿Ÿè¯„ä¼°å®Œæˆï¼"

echo "ğŸ§ª å¼€å§‹ ARC-Challenge ç²¾åº¦è¯„ä¼°..."
lm-eval --model vllm \
  --model_args pretrained="$MODEL_PATH",gpu_memory_utilization=$GPU_UTILIZATION,dtype=$DTYPE \
  --tasks arc_challenge \
  --batch_size $BATCH_SIZE \
  --output_path $OUTPUT_PATH

echo "âœ… ARC-Challenge ç²¾åº¦è¯„ä¼°å®Œæˆï¼"

echo "ğŸ§ª å¼€å§‹ GSM8K ç²¾åº¦è¯„ä¼°..."
lm-eval --model vllm \
  --model_args pretrained="$MODEL_PATH",gpu_memory_utilization=$GPU_UTILIZATION,dtype=$DTYPE \
  --tasks gsm8k \
  --batch_size $BATCH_SIZE \
  --output_path $OUTPUT_PATH

echo "âœ… GSM8K ç²¾åº¦è¯„ä¼°å®Œæˆï¼"
echo "ğŸ‰ æ‰€æœ‰è¯„ä¼°æµç¨‹å®Œæˆï¼ç»“æœä¿å­˜åœ¨ $OUTPUT_PATH"
